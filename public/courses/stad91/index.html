<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>STAD91 Winter 2026 - Bayesian Statistical Inference | Thibault Randrianarisoa</title>
<meta name="keywords" content="Decision Theory, Priors, Posteriors, Bayesian tests, Model selection, Sampling Algorithms, Variational Bayes, Asymptotics, Gaussian Processes, High-dimensional models, Dirichlet process">
<meta name="description" content="This undergraduate/graduate course presents some modern techniques for probabilistic machine learning.">
<meta name="author" content="Thibault Randrianarisoa">
<link rel="canonical" href="http://localhost:1313/courses/stad91/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.9f14d0c248daea29ce935b53a3e41f3fab665ebe18ec26af2ba02a16ac629ad0.css" integrity="sha256-nxTQwkja6inOk1tTo&#43;QfP6tmXr4Y7CavK6AqFqximtA=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/courses/stad91/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript><meta property="og:title" content="STAD91 Winter 2026 - Bayesian Statistical Inference" />
<meta property="og:description" content="This undergraduate/graduate course presents some modern techniques for probabilistic machine learning." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://localhost:1313/courses/stad91/" />
<meta property="og:image" content="http://localhost:1313/stad91.png" /><meta property="article:section" content="courses" />
<meta property="article:published_time" content="2026-01-05T00:00:00+00:00" />
<meta property="article:modified_time" content="2026-01-05T00:00:00+00:00" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="http://localhost:1313/stad91.png" />
<meta name="twitter:title" content="STAD91 Winter 2026 - Bayesian Statistical Inference"/>
<meta name="twitter:description" content="This undergraduate/graduate course presents some modern techniques for probabilistic machine learning."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Courses",
      "item": "http://localhost:1313/courses/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "STAD91 Winter 2026 - Bayesian Statistical Inference",
      "item": "http://localhost:1313/courses/stad91/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "STAD91 Winter 2026 - Bayesian Statistical Inference",
  "name": "STAD91 Winter 2026 - Bayesian Statistical Inference",
  "description": "This undergraduate/graduate course presents some modern techniques for probabilistic machine learning.",
  "keywords": [
    "Decision Theory", "Priors", "Posteriors", "Bayesian tests", "Model selection", "Sampling Algorithms", "Variational Bayes", "Asymptotics", "Gaussian Processes", "High-dimensional models", "Dirichlet process"
  ],
  "articleBody": " Introduction This course introduces the core concepts of Bayesian statistics, the theoretical properties of Bayesian estimators and their use in decision-making under uncertainty. You will learn key Bayesian modelling approaches and advanced computational techniques tailored to the needs and structure of different models.\nWe begin with parametric models to introduce the core ideas of Bayesian analysis, covering prior specification, inference (point estimation, credible sets, and hypothesis testing), its decision-theoretic foundations, and key asymptotic results such as posterior consistency and the Bernstein–von Mises theorem. We will also study modern computational methods for Bayesian inference and introduce more advanced topics, including high-dimensional and nonparametric models. For these models, we will focus primarily on prior construction and on results about convergence rates and adaptation.\nMore details can be found in syllabus, quercus and piazza (Access Code: n0px27jcbmb).\nAnnouncements Lectures begin on Jan 8! Instructor Thibault Randrianarisoa, Office: IA 4064 Email: t.randrianarisoa@utoronto.ca (put “STA414” in the subject) Office hours: Thursday 10am–1pm Teaching Assistants TBA\nThey will handle all questions related to homework assigments, the midterm and the final exam. Email: TBA (in the subject of the email indicate the scope: HW1, HW2, general, etc) Time \u0026 Location Thursday, 3:00 PM - 6:00 PM\nIn Person: IA 1160\nSuggested Reading The course will be based on some of the content of the book Bayesian Data Analysis (BDA) by Gelman, Carlin, Stern, Dunson, Vehtari \u0026 Rubin. It is freely available online on home page for the book https://sites.stat.columbia.edu/gelman/book/, which also contains additional material (lecture notes, code demo,…).\nAdditional suggested readings are:\n(TBC) Christian P. Robert (2007) The Bayesian Choice (MCSM) Christian P. Robert and George Casella (2004) Monte Carlo Statistical Methods (BC) Jean-Michel Marin and Christian P. Robert. (2007), Bayesian Core : A Practical Approach to Computational Bayesian Statistics Lectures and (tentative) timeline Week Lectures Suggested reading Problems Timeline Week 1 5-11 January Introduction and reminders of Statistics and Probability PS1.pdf Week 2 12-18 January Choice of priors, Aspects of the posterior Week 3 19-25 January Decision theory Week 4 26 January-1 February Bayesian tests, Model selection Week 5 2–8 February Sampling Algorithms Week 6 9–15 February Variational Bayes Week 7 16-22 February Reading Week Week 8 23 February – 1 March Midterm Week 9 2–8 March Asymptotic properties in parametric Bayesian models Week 109–15 March Priors for high-dimensional models Week 11 16–22 March Dirichlet process Week 12 23–29 March Gaussian processes Week 13 30 March - 5 April Asymptotics in Bayesian nonparametrics Homeworks Homework # Out Due TA Office Hours Solutions Assignment 1 TBD TBD TBD Assignment 2 TBD TBD TBD Computing Resources For the homework assignments, we will primarily use Python, and libraries such as NumPy, SciPy, and scikit-learn. You have two options:\nThe easiest option is run everything on Google Colab. Alternatively, you can install everything yourself on your own machine. If you don’t already have python, install using Anaconda. Use pip to install the required packages pip install scipy numpy autograd matplotlib jupyter sklearn For those unfamiliar with Numpy, there are many good resources, e.g. Numpy tutorial and Numpy Quickstart. ",
  "wordCount" : "508",
  "inLanguage": "en",
  "image":"http://localhost:1313/stad91.png","datePublished": "2026-01-05T00:00:00Z",
  "dateModified": "2026-01-05T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Thibault Randrianarisoa"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://localhost:1313/courses/stad91/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Thibault Randrianarisoa",
    "logo": {
      "@type": "ImageObject",
      "url": "http://localhost:1313/favicon.ico"
    }
  }
}
</script>



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" integrity="sha384-wcIxkf4k558AjM3Yz3BBFQUbk/zgIYC2R0QpeeYb+TwlBVMrlgLqwRjRtGZiK7ww" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.js" integrity="sha384-hIoBPJpTUs74ddyc4bFZSM1TVlQDA60VBbJS0oA934VSz82sBx1X7kSx2ATBDIyd" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/contrib/auto-render.min.js" integrity="sha384-43gviWU0YVjaDtb/GhzOouOXtZMP/7XUzwPTstBeZFe/+rCMvRwr4yROQP43s0Xk" crossorigin="anonymous"
  onload="renderMathInElement(document.body);"></script>

<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          delimiters: [
            {left: '$$', right: '$$', display: true},
            {left: '$', right: '$', display: false},
            {left: "\\begin{equation}", right: "\\end{equation}", display: true},
            {left: "\\begin{equation*}", right: "\\end{equation*}", display: true},
            {left: "\\begin{align}", right: "\\end{align}", display: true},
            {left: "\\begin{align*}", right: "\\end{align*}", display: true},
            {left: "\\begin{alignat}", right: "\\end{alignat}", display: true},
            {left: "\\begin{gather}", right: "\\end{gather}", display: true},
            {left: "\\begin{CD}", right: "\\end{CD}", display: true},
          ],
          throwOnError : false
        });
    });
</script>
 


</head>

<body class="" id="top">

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="Thibault Randrianarisoa">
                <img src="http://localhost:1313/favicon.ico" alt="" aria-label="logo"
                    height="18"
                    width="18">Thibault Randrianarisoa</a>
            <div class="logo-switches">
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/publications/" title="Publications">
                    <span>Publications</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/teaching/" title="Teaching">
                    <span>Teaching</span>
                </a>
            </li>
        </ul>
    </nav>
</header>

    <main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      STAD91 Winter 2026 - Bayesian Statistical Inference
    </h1>
    <div class="post-meta"><span title='2026-01-05 00:00:00 +0000 UTC'>January 2026</span>&nbsp;&middot;&nbsp;Thibault Randrianarisoa

</div>
  </header> <div class="toc">
    <details  open>
        <summary accesskey="c">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><nav id="TableOfContents">
  <ul>
    <li><a href="#introduction">Introduction</a></li>
    <li><a href="#announcements">Announcements</a></li>
    <li><a href="#instructor">Instructor</a></li>
    <li><a href="#teaching-assistants">Teaching Assistants</a></li>
    <li><a href="#time--location">Time &amp; Location</a></li>
    <li><a href="#suggested-reading">Suggested Reading</a></li>
    <li><a href="#lectures-and-tentative-timeline">Lectures and (tentative) timeline</a></li>
    <li><a href="#homeworks">Homeworks</a></li>
    <li><a href="#computing-resources">Computing Resources</a></li>
  </ul>
</nav>
        </div>
    </details>
</div>

  <div class="post-content"><p><img loading="lazy" src="stad91.png" alt="Alt text"  />
</p>
<h2 id="introduction">Introduction<a hidden class="anchor" aria-hidden="true" href="#introduction">#</a></h2>
<p>This course introduces the core concepts of Bayesian statistics, the theoretical properties of Bayesian estimators and
their use in decision-making under uncertainty. You will learn key Bayesian modelling approaches and advanced computational
techniques tailored to the needs  and structure of different models.</p>
<p>We begin with parametric models to introduce the core ideas of Bayesian analysis, covering prior specification, inference
(point estimation, credible sets, and hypothesis testing), its decision-theoretic foundations, and key asymptotic results
such as posterior consistency and the Bernstein–von Mises theorem. We will also study modern computational methods for
Bayesian inference and introduce more advanced topics, including high-dimensional and nonparametric models. For these models,
we will focus primarily on prior construction and on results about convergence rates and adaptation.</p>
<p>More details can be found in <a href="STAD91H3S-2026_Winter_Syllabus-20260105.pdf">syllabus</a>, <a href="https://q.utoronto.ca/courses/429453" target="_blank">quercus</a> and
<a href="https://piazza.com/utoronto.ca/winter2026/stad91h3" target="_blank">piazza</a>
(Access Code: n0px27jcbmb).</p>
<h2 id="announcements">Announcements<a hidden class="anchor" aria-hidden="true" href="#announcements">#</a></h2>
<ul>
<li>Lectures begin on Jan 8!</li>
</ul>
<h2 id="instructor">Instructor<a hidden class="anchor" aria-hidden="true" href="#instructor">#</a></h2>
<ul>
<li>Thibault Randrianarisoa, Office: IA 4064
<ul>
<li>Email: <a href="mailto:t.randrianarisoa@utoronto.ca">t.randrianarisoa@utoronto.ca</a> (put “STA414” in the subject)</li>
<li>Office hours: Thursday 10am–1pm</li>
</ul>
</li>
</ul>
<h2 id="teaching-assistants">Teaching Assistants<a hidden class="anchor" aria-hidden="true" href="#teaching-assistants">#</a></h2>
<p>TBA</p>
<ul>
<li>They will handle all questions related to homework assigments, the midterm and the final exam.</li>
<li>Email: TBA (in the subject of the email indicate the scope: HW1, HW2, general, etc)</li>
</ul>
<h2 id="time--location">Time &amp; Location<a hidden class="anchor" aria-hidden="true" href="#time--location">#</a></h2>
<p>Thursday, 3:00 PM - 6:00 PM</p>
<p>In Person: IA 1160</p>
<h2 id="suggested-reading">Suggested Reading<a hidden class="anchor" aria-hidden="true" href="#suggested-reading">#</a></h2>
<p>The course will be based on some of the content of the book <em>Bayesian Data Analysis</em> (BDA) by
Gelman, Carlin, Stern, Dunson, Vehtari &amp; Rubin. It is freely available online on home page for
the book <a href="https://sites.stat.columbia.edu/gelman/book/" target="_blank">https://sites.stat.columbia.edu/gelman/book/</a>, which also contains additional material
(lecture notes, code demo,&hellip;).</p>
<p>Additional suggested readings are:</p>
<ul>
<li>(TBC) Christian P. Robert (2007) <a href="https://errorstatistics.com/wp-content/uploads/2016/03/robert-20071.pdf" target="_blank">The Bayesian Choice</a></li>
<li>(MCSM) Christian P. Robert and George Casella (2004) <a href="https://www.inference.org.uk/mackay/itila/book.html" target="_blank">Monte Carlo Statistical Methods</a></li>
<li>(BC) Jean-Michel Marin and Christian P. Robert. (2007), <a href="https://link.springer.com/book/10.1007/978-0-387-38983-7" target="_blank">Bayesian Core : A Practical Approach to Computational Bayesian Statistics</a></li>
</ul>
<h2 id="lectures-and-tentative-timeline">Lectures and (tentative) timeline<a hidden class="anchor" aria-hidden="true" href="#lectures-and-tentative-timeline">#</a></h2>
<table>
  <thead>
      <tr>
          <th style="text-align: left">Week</th>
          <th style="text-align: left">Lectures</th>
          <th style="text-align: left">Suggested reading</th>
          <th style="text-align: left">Problems</th>
          <th style="text-align: left">Timeline</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: left">Week 1 <br/>5-11 January<br/></td>
          <td style="text-align: left"><a href="BS_Lec01.pdf">Introduction and reminders of Statistics and Probability</a></td>
          <td style="text-align: left"></td>
          <td style="text-align: left"><a href="PS1.pdf">PS1.pdf</a></td>
          <td style="text-align: left"></td>
      </tr>
      <tr>
          <td style="text-align: left">Week 2 <br/>12-18 January<br/></td>
          <td style="text-align: left">Choice of priors, Aspects of the posterior</td>
          <td style="text-align: left"></td>
          <td style="text-align: left"></td>
          <td style="text-align: left"></td>
      </tr>
      <tr>
          <td style="text-align: left">Week 3 <br/>19-25 January<br/></td>
          <td style="text-align: left">Decision theory</td>
          <td style="text-align: left"></td>
          <td style="text-align: left"></td>
          <td style="text-align: left"></td>
      </tr>
      <tr>
          <td style="text-align: left">Week 4 <br/>26 January-1 February<br/></td>
          <td style="text-align: left">Bayesian tests, Model selection</td>
          <td style="text-align: left"></td>
          <td style="text-align: left"></td>
          <td style="text-align: left"></td>
      </tr>
      <tr>
          <td style="text-align: left">Week 5 <br/>2–8 February<br/></td>
          <td style="text-align: left">Sampling Algorithms</td>
          <td style="text-align: left"></td>
          <td style="text-align: left"></td>
          <td style="text-align: left"></td>
      </tr>
      <tr>
          <td style="text-align: left">Week 6 <br/>9–15 February<br/></td>
          <td style="text-align: left">Variational Bayes</td>
          <td style="text-align: left"></td>
          <td style="text-align: left"></td>
          <td style="text-align: left"></td>
      </tr>
      <tr>
          <td style="text-align: left">Week 7 <br/>16-22 February<br/></td>
          <td style="text-align: left"><strong>Reading Week</strong></td>
          <td style="text-align: left"></td>
          <td style="text-align: left"></td>
          <td style="text-align: left"></td>
      </tr>
      <tr>
          <td style="text-align: left">Week 8 <br/>23 February – 1 March<br/></td>
          <td style="text-align: left"><strong>Midterm</strong></td>
          <td style="text-align: left"></td>
          <td style="text-align: left"></td>
          <td style="text-align: left"></td>
      </tr>
      <tr>
          <td style="text-align: left">Week 9 <br/>2–8 March<br/></td>
          <td style="text-align: left">Asymptotic properties in parametric Bayesian models</td>
          <td style="text-align: left"></td>
          <td style="text-align: left"></td>
          <td style="text-align: left"></td>
      </tr>
      <tr>
          <td style="text-align: left">Week 10<br/>9–15 March<br/></td>
          <td style="text-align: left">Priors for high-dimensional models</td>
          <td style="text-align: left"></td>
          <td style="text-align: left"></td>
          <td style="text-align: left"></td>
      </tr>
      <tr>
          <td style="text-align: left">Week 11 <br/>16–22 March<br/></td>
          <td style="text-align: left">Dirichlet process</td>
          <td style="text-align: left"></td>
          <td style="text-align: left"></td>
          <td style="text-align: left"></td>
      </tr>
      <tr>
          <td style="text-align: left">Week 12 <br/>23–29 March <br/></td>
          <td style="text-align: left">Gaussian processes</td>
          <td style="text-align: left"></td>
          <td style="text-align: left"></td>
          <td style="text-align: left"></td>
      </tr>
      <tr>
          <td style="text-align: left">Week 13 <br/>30 March - 5 April<br/></td>
          <td style="text-align: left">Asymptotics in Bayesian nonparametrics</td>
          <td style="text-align: left"></td>
          <td style="text-align: left"></td>
          <td style="text-align: left"></td>
      </tr>
  </tbody>
</table>
<h2 id="homeworks">Homeworks<a hidden class="anchor" aria-hidden="true" href="#homeworks">#</a></h2>
<table>
  <thead>
      <tr>
          <th style="text-align: left">Homework #</th>
          <th style="text-align: left">Out</th>
          <th style="text-align: left">Due</th>
          <th style="text-align: left">TA Office Hours</th>
          <th style="text-align: left">Solutions</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: left"><strong>Assignment 1</strong></td>
          <td style="text-align: left">TBD</td>
          <td style="text-align: left">TBD</td>
          <td style="text-align: left">TBD</td>
          <td style="text-align: left"></td>
      </tr>
      <tr>
          <td style="text-align: left"><strong>Assignment 2</strong></td>
          <td style="text-align: left">TBD</td>
          <td style="text-align: left">TBD</td>
          <td style="text-align: left">TBD</td>
          <td style="text-align: left"></td>
      </tr>
  </tbody>
</table>
<h2 id="computing-resources">Computing Resources<a hidden class="anchor" aria-hidden="true" href="#computing-resources">#</a></h2>
<p>For the homework assignments, we will primarily use Python, and libraries such as <a href="https://numpy.org/" target="_blank">NumPy</a>,
<a href="https://scipy.org/" target="_blank">SciPy</a>, and <a href="https://scikit-learn.org/stable/" target="_blank">scikit-learn</a>. You have two options:</p>
<ul>
<li>The easiest option is run everything on <a href="https://colab.research.google.com/" target="_blank">Google Colab</a>.</li>
<li>Alternatively, you can install everything yourself on your own machine.
<ul>
<li>If you don’t already have python, install using <a href="https://www.anaconda.com/download" target="_blank">Anaconda</a>.</li>
<li>Use pip to install the required packages <code>pip install scipy numpy autograd matplotlib jupyter sklearn</code></li>
</ul>
</li>
<li>For those unfamiliar with Numpy, there are many good resources, e.g. <a href="https://realpython.com/numpy-tutorial/" target="_blank">Numpy tutorial</a>
and <a href="https://numpy.org/doc/stable/user/quickstart.html" target="_blank">Numpy Quickstart</a>.</li>
</ul>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://localhost:1313/tags/decision-theory/">Decision Theory</a></li>
      <li><a href="http://localhost:1313/tags/priors/">Priors</a></li>
      <li><a href="http://localhost:1313/tags/posteriors/">Posteriors</a></li>
      <li><a href="http://localhost:1313/tags/bayesian-tests/">Bayesian Tests</a></li>
      <li><a href="http://localhost:1313/tags/model-selection/">Model Selection</a></li>
      <li><a href="http://localhost:1313/tags/sampling-algorithms/">Sampling Algorithms</a></li>
      <li><a href="http://localhost:1313/tags/variational-bayes/">Variational Bayes</a></li>
      <li><a href="http://localhost:1313/tags/asymptotics/">Asymptotics</a></li>
      <li><a href="http://localhost:1313/tags/gaussian-processes/">Gaussian Processes</a></li>
      <li><a href="http://localhost:1313/tags/high-dimensional-models/">High-Dimensional Models</a></li>
      <li><a href="http://localhost:1313/tags/dirichlet-process/">Dirichlet Process</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2026 <a href="http://localhost:1313/">Thibault Randrianarisoa</a></span> ·     
    <span>
    Powered by 
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/pmichaillat/hugo-website/" rel="noopener" target="_blank">a modified version</a>
         of 
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>
</html>
